---
title: "Assignment7"
author: "xiaoyi"
date: "13/11/2021"
output: html_document
---
# 1
```{r}
library(tidyverse)
library(Stat2Data)

data("Hawks")
Hawks
df<-Hawks%>%
  filter(Species == "RT")%>%
  select(Weight)%>%
  na.omit()
df

Weight_mean = mean(df$Weight, na.rm = 1) 



t.test(x=df$Weight, conf.level = 0.99, mu = Weight_mean)
 


ggplot(data = df, aes(x=Weight))+geom_density()+xlab("Weight")

ggplot(data = df, aes(sample=Weight))+stat_qq()+stat_qq_line(color="blue")

```
# 2
```{r}
library(palmerpenguins)

head(penguins)
df2<-penguins%>%
  filter(species == "Adelie")%>%
  mutate(bill_adelie = bill_length_mm)%>%
  select(bill_adelie)
  

t.test(x=df2$bill_adelie, mu = 40, conf.level = 0.99)
```

# 3
```{r}

one_sample_ttest<-function(x,mu_0)
{
  alpha<-0.01
  n<-length(x)
  t<-qt(1-alpha/2,df = n-1)
  p<-2*(1-pt(abs(t),df = n-1))
  return (p)
}

one_sample_ttest(df$Weight, Weight_mean)

```

# 4
```{r}
library(PairedData)
data("Barley")

df3<-as.data.frame(Barley)

df3<-df3%>%
  mutate(diff = df3$Glabron -df3$Velvet)

ggplot(data = df3,aes(x=diff))+geom_density()
ggplot(data = df3,aes(sample=diff))+stat_qq()+stat_qq_line()

df3

t.test(x = df3$Glabron, y = df3$Velvet, paired = TRUE, conf.level = 0.99)
```
# 5

```{r}

student_t_confidence_interval<-function(sample,confidence_level){
sample<-sample[!is.na(sample)] # remove any missing values 
n<-length(sample)
# compute sample size 
mu_est<-mean(sample) 
# compute sample mean 
sig_est<-sd(sample) 
# compute sample sd
alpha = 1-confidence_level 
# alpha from gamma 
t<-qt(1-alpha/2,df=n-1) 
# get student t quantile 
l=mu_est-(t/sqrt(n))*sig_est 
# lower 
u=mu_est+(t/sqrt(n))*sig_est # upper
  return(c(l,u))
}

num_trials<-100000
sample_size<-30
mu_0<-1
sigma_0<-3
alpha<-0.05
set.seed(0) # set random seed for reproducibility
single_alpha_coverage_simulation_df<-data.frame(trial=seq(num_trials))%>%   
  mutate(sample=map(.x=trial,.f=~rnorm(n=sample_size,mean=mu_0,sd=sigma_0)))%>%
  # generate random Gaussian samples
  mutate(ci_interval=map(.x=sample,.f=~student_t_confidence_interval(.x,1-alpha)))%>% 
  #generate confidence intervals
  mutate(cover=map_lgl(.x=ci_interval,.f=~((min(.x)<=mu_0)&(max(.x)>=mu_0))))%>% 
  # check if interval covers mu_0
  mutate(ci_length=map_dbl(.x=ci_interval,.f=~(max(.x)-min(.x))))
  # compute interval length

  single_alpha_coverage_simulation_df%>% pull(cover)%>%
  mean() # estimate of coverage probability



```
```{r}

num_trials<-1000
sample_size<-30
mu_0<-1
sigma_0<-3
##???
variable_alpha_coverage_prob<-function(alpha)  {
  single_alpha_coverage_simulation_df<-data.frame(trial=seq(num_trials))%>%  
  mutate(sample=map(.x=trial,.f=~rnorm(n=sample_size,mean=mu_0,sd=sigma_0)))%>%
  # generate random Gaussian samples
  mutate(ci_interval=map(.x=sample,.f=~student_t_confidence_interval(.x,1-alpha)))%>% 
  #generate confidence intervals
  mutate(cover=map_lgl(.x=ci_interval,.f=~((min(.x)<=mu_0)&(max(.x)>=mu_0))))%>% 
  # check if interval covers mu_0
  mutate(ci_length=map_dbl(.x=ci_interval,.f=~(max(.x)-min(.x))))
  # compute interval length
  
  single_alpha_coverage_simulation_df%>% pull(cover)%>%
  mean() # estimate of coverage probability
}
single_alpha_coverage_simulation_df

alpha_v<-seq(0.01,1,0.1)
variable_alpha_coverage_simulation_df<-data.frame(alpha_v)%>%
  mutate(mean_cover_prob = map_dbl(.x=alpha_v,.f=variable_alpha_coverage_prob))

variable_alpha_coverage_simulation_df
```

```{r}
variable_alpha_coverage_simulation_df%>%
  ggplot(aes(x=1-alpha_v, y = mean_cover_prob))+
  geom_line()
```

```{r}
variable_alpha_ci_length<-function(alpha)  {
  single_alpha_coverage_simulation_df<-data.frame(trial=seq(num_trials))%>%  
  mutate(sample=map(.x=trial,.f=~rnorm(n=sample_size,mean=mu_0,sd=sigma_0)))%>%
  # generate random Gaussian samples
  mutate(ci_interval=map(.x=sample,.f=~student_t_confidence_interval(.x,1-alpha)))%>% 
  #generate confidence intervals
  mutate(cover=map_lgl(.x=ci_interval,.f=~((min(.x)<=mu_0)&(max(.x)>=mu_0))))%>% 
  # check if interval covers mu_0
  mutate(ci_length=map_dbl(.x=ci_interval,.f=~(max(.x)-min(.x))))
  # compute interval length
  return (mean( single_alpha_coverage_simulation_df$ci_length))
}

variable_alpha_ci_length_df<-data.frame(alpha_v)%>%
  mutate(ci_length = map_dbl(.x = alpha_v,.f =variable_alpha_ci_length ))

variable_alpha_ci_length_df
```
#6

```{r}
library(PropCIs)
driving_test_results<-c(1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,1,0) 
alpha<-0.01 # failure probability
num_successes<- sum(driving_test_results) # total passes
sample_size<-length(driving_test_results)
ci=scoreci(x=num_successes, n=sample_size, conf.level=1-alpha) 
# compute Wilson's confidence intervals

```
```{r}
alpha<-0.05
df4<-df%>%
  mutate(weight_more_1kg = map_lgl(.x=Weight, .f= ~(.x >= 1000)))
scoreci(x=sum(df4$weight_more_1kg), n=length(df4$weight_more_1kg), conf.level=1-alpha) 

```
# 7
```{r}
library(Stat2Data)
data("Airlines")
Airlines
df7<-Airlines%>%
  filter(airline ==  'Delta' & airport == 'ORD')%>%
  mutate(OnTime = map_lgl(.x=OnTime,.f = ~(.x=='yes')))
df7
binom.test(x=sum(df7$OnTim), n=length(df7$OnTime),p = 0.875, alternative = "two.sided")
```
# 8
```{r}
library(boot) # load the library set.seed(123) # set random seed
library(tidyverse)
library(palmerpenguins)
#first define a function which computes the mean of a column of interest
compute_mean<-function(df,indicies,col_name){ sub_sample<-df%>%slice(indicies)%>%pull(all_of(col_name)) # extract subsample
return(mean(sub_sample,na.rm=1))}# return median
# use the boot function to generate the bootstrap statistics
results<-boot(data = penguins,statistic =compute_mean,col_name="body_mass_g",R = 1000)
# compute the 95%-level confidence interval for the mean
boot.ci(boot.out = results, type = "basic",conf=0.95)


#first define a function which computes the median of a column of interest
compute_median<-function(df,indicies,col_name){ sub_sample<-df%>%slice(indicies)%>%pull(all_of(col_name)) # extract subsample
return(median(sub_sample,na.rm=1))}# return median
# use the boot function to generate the bootstrap statistics
median_results<-boot(data = Hawks, statistic =compute_median,col_name="Weight",R = 1000)
# compute the 95%-level confidence interval for the median
boot.ci(boot.out = median_results, type = "basic",conf=0.99)

#mean
compute_mean<-function(df,indicies,col_name){ sub_sample<-df%>%slice(indicies)%>%pull(all_of(col_name)) # extract subsample
return(mean(sub_sample,na.rm=1))}# return median
# use the boot function to generate the bootstrap statistics
results<-boot(data = Hawks,statistic =compute_mean,col_name="Weight",R = 1000)
# compute the 95%-level confidence interval for the mean
boot.ci(boot.out = results, type = "basic",conf=0.95)
```

# 9
```{r}
set.seed(0)
n<-100
q<-0.5
library(broom)

CIinterval<-function(y,alpha){
  ci_a = tidy(scoreci(x=sum(y), n, conf.level=1-alpha))
  return (c(ci_a$conf.low,ci_a$conf.high))
}



ci_cover_q_prob<-function(alpha){
  binom_simulation_df<-data.frame(trial = seq(1000))%>%
  mutate(sample = map(.x = trial,
                      .f=~rbinom(n,1,q)))%>%
  mutate(ci_interval = map(.x=sample, 
                           .f = ~CIinterval(.x,alpha)))%>%
  mutate(cover=map_lgl(.x=ci_interval,.f=~((min(.x)<=q)&(max(.x)>=q))))%>% 
  # check if interval covers mu_0
  mutate(ci_length=map_dbl(.x=ci_interval,.f=~(max(.x)-min(.x))))
  # compute interval length
  
  binom_simulation_df%>% pull(cover)%>%
  mean()
}

binom_simulation_df
CI_interval(0.1,0.5)
ci_cover_q_prob(0.5)

alpha_v=seq(0.5,1,0.001)
df9<-data.frame(alpha_v)%>%
  mutate(prob = map_dbl(.x = alpha_v, .f=ci_cover_q_prob))

```
```{r}
df9%>%
ggplot(aes(x=alpha_v, y=prob))+
  geom_smooth()
```

